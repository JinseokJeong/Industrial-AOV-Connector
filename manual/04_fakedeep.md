# This page will tell you how to achieve deep compositing

### **What is deep compositing and fakedeep? **

**Deep Compositing** refers to a advanced compositing technique used in visual effects (VFX) and film post-production, where multi-layered depth data (including Z-depth, color, and transparency values) is utilized to precisely manage complex spatial relationships between elements in a 3D environment. Unlike traditional "flat" compositing, which relies solely on 2D RGBA channels, Deep Compositing stores depth information for every pixel across multiple layers, enabling accurate handling of overlapping elements like transparent objects (e.g., glass, smoke), fine details (e.g., hair, particles), and dynamic depth-based effects. By leveraging operations such as **DeepMerge** and **DeepRecolor**, artists can seamlessly blend CGI elements with live-action footage, adjust depth-of-field or object positions post-render, and automate matte generation without manual rotoscoping. This approach ensures physically accurate interactions between layers, reduces rendering iterations, and streamlines workflows for integrating volumetrics, explosions, or other intricate effects. Tools like **DeepRead** and **DeepToImage** in Nuke allow artists to import, visualize, and manipulate Deep EXR files (generated by renderers like Arnold or RenderMan), making it a cornerstone of modern VFX pipelines for its efficiency, flexibility, and precision.

**Fakedeep** is a method to make deep from blender's depth channel. A fake deep channel must have precise pixel that matches beauty pass. That's why we need to use the material's depth output.

### **How to do deep compositing with fake deep channel? **

To use fake deep for deep compositing, there do have some limitations when rendering: 

1. You may not render motion blur, that ruins the edge pixel, you can only do motion blur after deep merge
2. Volume elements are very hard to get their fake deep, and can only store 1 layer of depth info, which normally need multiple layers of depth info
3. if the objects are intersecting with each other, deep cutted edges will wiggle, because the precision is not high enough like a normal deep layer

If you already familier with those things, we can move on to the actual performing.

You need 1 gizmo, the [color smear](https://github.com/RichFrazer/colour-smear-for-Nuke/blob/master/colour-smear.nk). This node will help erode out the fake deep's edge pixels, remove the dramatic value change because of antialias when rendering. 

First, Shuffle the fake deep and your beauty's alpha channel into rgba like this:
<img width="681" alt="屏幕截图 2025-03-24 235033" src="https://github.com/user-attachments/assets/cabc27ab-516c-4aee-b38c-a46d9132cdff" />

Then you plugin the color smear, remove all bright edges (depending on the distance, you may need to adjust the exposure of your viewer):
<img width="1033" alt="屏幕截图 2025-03-24 235200" src="https://github.com/user-attachments/assets/7713194e-3547-4e4f-8de3-337ff1e989ed" />

Finally, shuffle the processd rgba back to depth channel:
<img width="686" alt="屏幕截图 2025-03-24 235404" src="https://github.com/user-attachments/assets/249b9baa-0936-4c98-b2df-18ed31fc60ed" />

Now you just plug in the deep from image node, you get the deep layer. 

Have some fun!
